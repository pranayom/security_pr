"""Rendering for AuditReport — Rich console and Markdown output."""

from __future__ import annotations

import json

from oss_maintainer_toolkit.gatekeeper.models import AuditReport


FLAG_DESCRIPTIONS = {
    "temporal_clustering": "Multiple new-account PRs within 24h window",
    "first_contribution": "No prior merged PRs on this repo",
    "sensitive_paths": "Touches security-relevant code paths",
    "low_test_ratio": "Code added without proportional tests",
    "new_account": "GitHub account < 90 days old",
    "large_diff_hiding": "Large PR with small sensitive changes buried in bulk",
    "unjustified_deps": "Dependency changes without explanation in PR body",
}


def audit_report_to_json(report: AuditReport) -> str:
    """Serialize AuditReport to JSON string."""
    return report.model_dump_json(indent=2)


def audit_report_to_markdown(report: AuditReport) -> str:
    """Generate a shareable Markdown triage report from an AuditReport."""
    n = report.prs_analyzed
    if n == 0:
        return f"# Backlog Audit: {report.owner}/{report.repo}\n\nNo PRs analyzed."

    ft = report.fast_track_count
    rr = report.review_required_count
    rc = report.recommend_close_count

    lines = [
        f"# Backlog Audit: {report.owner}/{report.repo}",
        "",
        f"**Scope:** {n} most recent open PRs out of {report.total_open_prs:,} total",
        f"**Runtime:** {report.elapsed_seconds:.0f} seconds",
        "",
    ]
    if report.vision_document:
        lines.append(f"**Vision document:** {report.vision_document}")
        lines.append("")

    # Verdict distribution
    lines += [
        "## Verdict Distribution",
        "",
        "| Verdict | Count | % | Meaning |",
        "|---|---|---|---|",
        f"| FAST_TRACK | {ft} | {_pct(ft, n)} | Passed all checks |",
        f"| REVIEW_REQUIRED | {rr} | {_pct(rr, n)} | Flagged by heuristics |",
        f"| RECOMMEND_CLOSE | {rc} | {_pct(rc, n)} | Likely duplicate |",
        "",
    ]

    # Duplicate clusters
    lines += [
        "## Duplicate Clusters",
        "",
        f"- 0.90 threshold: **{len(report.clusters_090)} clusters** "
        f"({sum(len(c.members) for c in report.clusters_090)} PRs)",
        f"- 0.85 threshold: **{len(report.clusters_085)} clusters** "
        f"({sum(len(c.members) for c in report.clusters_085)} PRs)",
        f"- 0.80 threshold: **{len(report.clusters_080)} clusters** "
        f"({sum(len(c.members) for c in report.clusters_080)} PRs)",
        "",
    ]

    for i, cluster in enumerate(report.clusters_090, 1):
        anchor = cluster.members[0]
        lines += [
            f"**Cluster {i}: {anchor['title'][:60]}**",
            "",
            "| PR | Title | Author | Similarity |",
            "|---|---|---|---|",
        ]
        for m in cluster.members:
            sim_str = "anchor" if m["similarity"] == 0.0 else f"{m['similarity']:.3f}"
            lines.append(f"| #{m['pr']} | {m['title'][:70]} | {m['author']} | {sim_str} |")
        lines.append("")

    # Highest-risk
    if report.highest_risk:
        lines += [
            "## Highest-Risk PRs",
            "",
            "| PR | Title | Flags | Score | Risk Factors |",
            "|---|---|---|---|---|",
        ]
        for entry in report.highest_risk:
            title_short = entry.title[:55] + ("..." if len(entry.title) > 55 else "")
            flag_names = ", ".join(entry.flags)
            lines.append(
                f"| #{entry.pr_number} | {title_short} | "
                f"{entry.flag_count} ({entry.high_severity_count}H) | "
                f"{entry.score:.2f} | {flag_names} |"
            )
        lines.append("")

    # Flag frequency
    if report.flag_frequency:
        lines += [
            "## Flag Frequency",
            "",
            "| Flag | Count | % | Description |",
            "|---|---|---|---|",
        ]
        for flag_id, count in report.flag_frequency.items():
            desc = FLAG_DESCRIPTIONS.get(flag_id, flag_id)
            lines.append(f"| {flag_id} | {count} | {_pct(count, n)} | {desc} |")
        lines.append("")

    # Contributor stats
    lines += [
        "## Contributor Profile",
        "",
        "| Metric | Value |",
        "|---|---|",
        f"| Unique authors | {report.unique_authors} |",
        f"| First-time contributors | {report.first_time_contributors} ({_pct(report.first_time_contributors, n)}) |",
        f"| New accounts (< 90 days) | {report.new_accounts} ({_pct(report.new_accounts, n)}) |",
        f"| PRs touching sensitive paths | {report.sensitive_path_prs} ({_pct(report.sensitive_path_prs, n)}) |",
        f"| PRs with low test ratio | {report.low_test_prs} ({_pct(report.low_test_prs, n)}) |",
        "",
        "---",
        "",
        f"*Generated by [OSS Maintainer Toolkit](https://github.com/pranayom/oss-maintainer-toolkit)*",
    ]

    return "\n".join(lines)


def render_audit_report(report: AuditReport, console) -> None:
    """Render an AuditReport using Rich console."""
    from rich.panel import Panel
    from rich.table import Table

    n = report.prs_analyzed

    # Header
    console.print(Panel(
        f"[bold]{report.owner}/{report.repo}[/bold] — "
        f"{n} PRs analyzed out of {report.total_open_prs:,} total\n"
        f"Runtime: {report.elapsed_seconds:.0f}s"
        + (f" | Vision: {report.vision_document}" if report.vision_document else ""),
        title="Backlog Audit",
    ))

    # Verdict table
    table = Table(title="Verdict Distribution")
    table.add_column("Verdict", style="bold")
    table.add_column("Count", justify="right")
    table.add_column("%", justify="right")
    table.add_row("[green]FAST_TRACK[/green]", str(report.fast_track_count), _pct(report.fast_track_count, n))
    table.add_row("[yellow]REVIEW_REQUIRED[/yellow]", str(report.review_required_count), _pct(report.review_required_count, n))
    table.add_row("[red]RECOMMEND_CLOSE[/red]", str(report.recommend_close_count), _pct(report.recommend_close_count, n))
    console.print(table)

    # Clusters
    console.print(f"\n[bold]Duplicate Clusters:[/bold] "
                  f"0.90: {len(report.clusters_090)}, "
                  f"0.85: {len(report.clusters_085)}, "
                  f"0.80: {len(report.clusters_080)}")

    # Highest-risk
    if report.highest_risk:
        risk_table = Table(title="Highest-Risk PRs")
        risk_table.add_column("PR")
        risk_table.add_column("Title")
        risk_table.add_column("Flags", justify="right")
        risk_table.add_column("Score", justify="right")
        risk_table.add_column("Risk Factors")
        for entry in report.highest_risk[:10]:
            risk_table.add_row(
                f"#{entry.pr_number}",
                entry.title[:50],
                f"{entry.flag_count} ({entry.high_severity_count}H)",
                f"{entry.score:.2f}",
                ", ".join(entry.flags),
            )
        console.print(risk_table)

    # Flag frequency
    if report.flag_frequency:
        flag_table = Table(title="Flag Frequency")
        flag_table.add_column("Flag")
        flag_table.add_column("Count", justify="right")
        flag_table.add_column("%", justify="right")
        for flag_id, count in report.flag_frequency.items():
            flag_table.add_row(flag_id, str(count), _pct(count, n))
        console.print(flag_table)

    # Contributor stats
    console.print(f"\n[bold]Contributors:[/bold] "
                  f"{report.unique_authors} unique | "
                  f"{report.first_time_contributors} first-time | "
                  f"{report.new_accounts} new accounts")


def _pct(value: int, total: int) -> str:
    """Format a percentage string, handling zero division."""
    if total == 0:
        return "0%"
    return f"{value * 100 // total}%"
